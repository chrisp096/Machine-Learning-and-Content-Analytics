{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports / Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import filterfalse as ifilterfalse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'NEITHER': 0,\n",
    "    'EVIDENCE': 1,\n",
    "    'CLAIM': 2,\n",
    "    'NONE': 0\n",
    "}\n",
    "\n",
    "def load_corpus(path, label_mapping=None):\n",
    "    with open(path) as fp:\n",
    "        corpus = json.load(fp)\n",
    "\n",
    "    documents, texts, labels = [], [], []\n",
    "    for abstract in corpus:\n",
    "        documents.append(abstract)\n",
    "        texts.append(corpus[abstract]['sentences'])\n",
    "        if isinstance(label_mapping, dict):\n",
    "            labels.append(\n",
    "                [label_mapping[str(l).upper()]\n",
    "                    for l in corpus[abstract]['labels']])\n",
    "        else:\n",
    "            labels.append([str(l).upper() for l in corpus[abstract]['labels']])\n",
    "\n",
    "    assert len(texts) == len(labels)\n",
    "    data = pd.DataFrame(\n",
    "        zip(documents, texts, labels),\n",
    "        columns=['document', 'sentences', 'labels'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read our 2 datasets and merge them in 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 length: 1017 abstracts\n",
      "Dataset 2 length: 1669 abstracts\n",
      "Dataset length: 2686 abstracts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi: 10.1001/jamaneurol.2017.2814</td>\n",
       "      <td>[Concordance Between Different Amyloid Immunoa...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi: 10.1001/jamaneurol.2017.4913</td>\n",
       "      <td>[Association of Changes in Plasma Neurofilamen...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi: 10.1002/2015gl067056</td>\n",
       "      <td>[Dynamically triggered slip leading to sustain...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            document  \\\n",
       "0  doi: 10.1001/jamaneurol.2017.2814   \n",
       "1  doi: 10.1001/jamaneurol.2017.4913   \n",
       "2          doi: 10.1002/2015gl067056   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Concordance Between Different Amyloid Immunoa...   \n",
       "1  [Association of Changes in Plasma Neurofilamen...   \n",
       "2  [Dynamically triggered slip leading to sustain...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2]  \n",
       "2                                 [0, 0, 0, 1, 1, 2]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = load_corpus('dataset_aueb_argument_v3.json' , label_mapping=label2id)\n",
    "print(f'Dataset 1 length: {len(data1)} abstracts')\n",
    "\n",
    "data2 = load_corpus('dataset.json' , label_mapping=label2id)\n",
    "print(f'Dataset 2 length: {len(data2)} abstracts')\n",
    "\n",
    "data = data1.append(data2)\n",
    "print(f'Dataset length: {len(data)} abstracts')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a datafrme with the 'doc_id' & 'sentences' and a dataframe with the 'doc_id' & 'labels' for each unique sentence in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Split to sentences\n",
    "sentences = data['sentences'].explode().reset_index().rename(\n",
    "    columns={'index': 'doc_id', 'sentences': 'sentence'})\n",
    "sentences.sentence = sentences.sentence.astype(\"string\")\n",
    "sentences.sentence = sentences.sentence.str.strip()\n",
    "\n",
    "#@title and the corresponding labels\n",
    "labels = pd.DataFrame(data['labels'].explode()).reset_index(drop = True).rename(\n",
    "    columns={'labels': 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dataframe with the splitted sentences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32004, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26076</th>\n",
       "      <td>1229</td>\n",
       "      <td>Only the FACT-G social/family well-being subsc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22784</th>\n",
       "      <td>985</td>\n",
       "      <td>Results At older ages, migrants in Europe were...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>687</td>\n",
       "      <td>These results show that the CSF Aβ1–42/Aβ1–40 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18730</th>\n",
       "      <td>606</td>\n",
       "      <td>An open question is what promise the integrati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16420</th>\n",
       "      <td>428</td>\n",
       "      <td>Marital quality remained positive over time.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id                                           sentence label\n",
       "26076    1229  Only the FACT-G social/family well-being subsc...     1\n",
       "22784     985  Results At older ages, migrants in Europe were...     1\n",
       "6593      687  These results show that the CSF Aβ1–42/Aβ1–40 ...     2\n",
       "18730     606  An open question is what promise the integrati...     0\n",
       "16420     428       Marital quality remained positive over time.     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([sentences,labels['label']], axis = 1)\n",
    "print(merged_data.shape)\n",
    "merged_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We observe that we have some sentences that are one word, so let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31093, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(merged_data)):\n",
    "    if (len(merged_data['sentence'][i].split()) < 2):\n",
    "        merged_data = merged_data.drop(i)\n",
    "        \n",
    "merged_data.reset_index(inplace = True, drop = True)\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0 means no argument\n",
    "* 1 means Evidence\n",
    "* 2 means Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21471\n",
       "1     6203\n",
       "2     3419\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69.05\n",
       "1    19.95\n",
       "2    11.00\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(merged_data.label.value_counts() / len(merged_data) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We observe that we almost 70% of our sentences have no label so it is going to make our classifier predict it with higher probability since we have imbalanced dataset\n",
    "\n",
    "\n",
    "* Now let's check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_id      0\n",
       "sentence    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we have no Na's in our dataset so we can proceed.\n",
    "\n",
    "\n",
    "* Now let's see if we have any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['sentence'].duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have duplicates so let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing duplicates:  (31093, 3)\n",
      "Shape after removing duplicates:  (30862, 3)\n",
      "Rows Removed:  231\n"
     ]
    }
   ],
   "source": [
    "print('Shape before removing duplicates: ', merged_data.shape)\n",
    "a = merged_data.shape[0]\n",
    "merged_data.drop_duplicates(subset=['sentence'], inplace=True)\n",
    "print('Shape after removing duplicates: ', merged_data.shape)\n",
    "print('Rows Removed: ', a - merged_data.shape[0])\n",
    "\n",
    "merged_data.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's assign our X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_data['sentence']\n",
    "y = merged_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function to clean our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Pre process and convert texts to a list of words\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's have a look at a sentence before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This result is achieved through novel cross-link agents made by boron- and fluorine-containing heterocycles that can react between themselves upon UV- and white-light exposure.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[107]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the clean function we created to clean our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X['sentence']=X['sentence'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's have a look again at our X before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this result is achieved through novel cross link agents made by boron and fluorine containing heterocycles that can react between themselves upon uv and white light exposure '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['sentence'][107]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset Procedure\n",
    "\n",
    "\n",
    "* We split the dataset to 80% train and 20% test.\n",
    "* We use a random state in order to split the same every time we run the code.\n",
    "* We use stratification in order to have equal representation of all labels in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X['sentence'],\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    68.97\n",
      "1    20.00\n",
      "2    11.03\n",
      "Name: label, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    68.98\n",
       "1    19.99\n",
       "2    11.03\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(round(y_train.value_counts() / len(y_train) * 100, 2))\n",
    "round(y_test.value_counts() / len(y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We observe that the stratification was successful so let's proceed.\n",
    "\n",
    "\n",
    "* Let's create a dataframe with the senteces and their corresponding labels of our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30013</th>\n",
       "      <td>patients who failed previous monotherapy remai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14079</th>\n",
       "      <td>introduction pediatric road traffic injuries r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>here we report the rationalization of the high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence label\n",
       "30013  patients who failed previous monotherapy remai...     1\n",
       "14079  introduction pediatric road traffic injuries r...     0\n",
       "1548   here we report the rationalization of the high...     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x_train)\n",
    "df.columns = ['sentence']\n",
    "df[\"label\"] = y_train\n",
    "df['sentence'] = df.sentence.str.strip()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create one dataframe for the sentences that are evidence (label = 1) and one for the claims (label = 2) from the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidences = df[df[\"label\"] == 1]\n",
    "claims = df[df[\"label\"] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove stopwords, remove words with length < 4 and count word occurences for the dataframe with the sentences that are evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "corpora_1 = \" \".join(evidences['sentence'])\n",
    "words_1 = corpora_1.split()\n",
    "\n",
    "#Removing Stopwords\n",
    "filtered_sentence = []\n",
    "for w in words_1:\n",
    "    if w not in stops:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#remove words with length < 4\n",
    "filtered_sentence_v2 = []\n",
    "Counter(filtered_sentence).most_common()\n",
    "for w in filtered_sentence:\n",
    "    if len(w) > 3:\n",
    "        filtered_sentence_v2.append(w)      \n",
    "\n",
    "#Count how many times each unique word is present in all our sentences\n",
    "top_words_1 = Counter(filtered_sentence_v2).most_common()\n",
    "top_words_1 = top_words_1[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove stopwords, remove words with length < 4 and count word occurences for the dataframe with the sentences that are claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords and remove words with length < 3 \n",
    "stops = stopwords.words('english')\n",
    "corpora_2 = \" \".join(claims['sentence'])\n",
    "words_2 = corpora_2.split()\n",
    "\n",
    "filtered_sentence = []\n",
    "for w in words_2:\n",
    "    if w not in stops:\n",
    "        filtered_sentence.append(w)\n",
    "        \n",
    "filtered_sentence_v2 = []\n",
    "Counter(filtered_sentence).most_common()\n",
    "for w in filtered_sentence:\n",
    "    if len(w) > 3:\n",
    "        filtered_sentence_v2.append(w)      \n",
    "\n",
    "top_words_2 = Counter(filtered_sentence_v2).most_common()\n",
    "top_words_2 = top_words_2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('group', 893),\n",
       " ('patients', 802),\n",
       " ('significant', 479),\n",
       " ('months', 478),\n",
       " ('significantly', 451),\n",
       " ('results', 387),\n",
       " ('compared', 356),\n",
       " ('higher', 341),\n",
       " ('treatment', 339),\n",
       " ('mean', 335),\n",
       " ('groups', 316),\n",
       " ('respectively', 307),\n",
       " ('survival', 279),\n",
       " ('health', 270),\n",
       " ('associated', 260)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patients', 415),\n",
       " ('treatment', 255),\n",
       " ('results', 225),\n",
       " ('health', 203),\n",
       " ('study', 203),\n",
       " ('cancer', 200),\n",
       " ('conclusions', 196),\n",
       " ('associated', 167),\n",
       " ('well', 155),\n",
       " ('women', 154),\n",
       " ('conclusion', 154),\n",
       " ('climate', 153),\n",
       " ('effective', 133),\n",
       " ('findings', 125),\n",
       " ('risk', 119)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove common words that are present in the top words for both evidences and claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(top_words_1)):\n",
    "    if i >= len(top_words_1):\n",
    "        break\n",
    "    for j in range(len(top_words_2)):\n",
    "        if j >= len(top_words_2):\n",
    "            break\n",
    "        if top_words_1[i][0] == top_words_2[j][0]: #See if they contain the same word\n",
    "            top_words_2.pop(j)\n",
    "            top_words_1.pop(i)\n",
    "            i = 0\n",
    "            break\n",
    "            \n",
    "print(len(top_words_1))\n",
    "len(top_words_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keep only the words of each list without their occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['group', 'significant', 'months', 'significantly', 'compared']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_1_only = []\n",
    "for i in range(len(top_words_1)):\n",
    "    top_words_1_only.append(top_words_1[i][0])\n",
    "\n",
    "top_words_2_only = []\n",
    "for i in range(len(top_words_2)):\n",
    "    top_words_2_only.append(top_words_2[i][0])\n",
    "    \n",
    "top_words_1_only[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dataframe with the sentences and labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring summer and autumn verification scores c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>despite of the great number of studies on the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to investigate whether uterine artery emboliza...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anemia highly common among cancer patients is ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>methods nationally representative surveys of a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>there was no difference in bowel function betw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>the municipality of arnhem is one of dutch com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>the magnetic field noise referred to the pick ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>there is an old definition pointing to the fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>although 73 of the male students prefer to mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6173 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence label\n",
       "0     spring summer and autumn verification scores c...     0\n",
       "1     despite of the great number of studies on the ...     0\n",
       "2     to investigate whether uterine artery emboliza...     0\n",
       "3     anemia highly common among cancer patients is ...     2\n",
       "4     methods nationally representative surveys of a...     0\n",
       "...                                                 ...   ...\n",
       "6168  there was no difference in bowel function betw...     1\n",
       "6169  the municipality of arnhem is one of dutch com...     0\n",
       "6170  the magnetic field noise referred to the pick ...     0\n",
       "6171  there is an old definition pointing to the fir...     0\n",
       "6172  although 73 of the male students prefer to mar...     1\n",
       "\n",
       "[6173 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(x_test)\n",
    "df_test[\"label\"] = y_test\n",
    "df_test.reset_index(drop = True, inplace = True)\n",
    "#df_test['sentence'] = df_test.sentence.str.strip()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a new column with the predicted value, which has the value of 0 at start, and changes to 1 if it contains a word from top word list from evidences and 2 if it contains a word from top word list from claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-a19dc09e6efd>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predicted'][i] = 2\n",
      "<ipython-input-86-a19dc09e6efd>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predicted'][i] = 1\n"
     ]
    }
   ],
   "source": [
    "df_test['predicted'] = 0\n",
    "for i in range(len(df_test)):\n",
    "    for word in top_words_1_only:\n",
    "        if (word in df_test.sentence[i]):\n",
    "            df_test['predicted'][i] = 1\n",
    "    for word_2 in top_words_2_only:\n",
    "        if (word_2 in df_test.sentence[i]):\n",
    "            df_test['predicted'][i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4258\n",
       "1    1234\n",
       "2     681\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3483\n",
       "2    1780\n",
       "1     910\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.029969220800254"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_rate = (len(df_test[df_test['label'] == df_test['predicted']]) / len(df_test)) * 100\n",
    "success_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
